---
title: "Procedural Learning with Graded Entropy"
format:
  pdf:
    documentclass: article
    classoption: [10pt,letterpaper]
    pdf-engine: pdflatex
    template-partials:
      - before-body.tex
    include-in-header:
      text: |
        \usepackage{cogsci}
        \usepackage{pslatex}
    keep-tex: true
    cite-method: natbib
    natbiboptions: [numbers]
bibliography: CogSci_Template.bib
editor: source
---
```{r}
#| label: Load R libraries
#| echo: false
#| message: false

library(osfr)
library(dplyr)
library(tidyr)
library(tidyverse)
library(zoo)
library(jsonlite)
library(clipr)
library(here)
```

```{r}
#| label: Experiment configs that stay constant across participants
#| echo: false
#| include: false

EXPERIMENT_CONFIG <- list(
  datapipe_id_4x4 = "lpRUgvFf5pm4",
  osf_id_4x4 = "5zn6u",
  key_mapping_4pos = c("d","f","j","k"),
  key_mapping_5pos = c("s","d","f","j","k"),
  key_mapping_6pos = c("s","d","f","j","k","l"),
  key_mapping_7pos = c("a","s","d","f","j","k","l"),
  key_mapping_8pos = c("a","s","d","f","j","k","l",";"),
  n_blocks = 20,
  rsi = 120,
  error_feedback_duration = 200,
  error_tone_duration = 100,
  correct_feedback_duration = 200,
  estimated_trial_duration = 500,
  accuracy_threshold = 0.65,
	rt_threshold = 1000
)
```

# Abstract
::: {.abstract}
Your abstract text here. The abstract should be one paragraph. Following the abstract should be keywords.

**Keywords:** procedural learning, implicit learning, statistical learning
:::

# Introduction

Your introduction text here. You can cite references using `@NewellSimon1972a` or `[@ChalnickBillman1988a]`.

# Method

## Participants
```{r}
#| label: Demographic data
#| include: false
#| echo: false

df.demographics <- list.files(here("demographic-data/"), pattern = "*.csv", full.names=TRUE) %>%
  lapply(function(f) {
    matrix_size <- gsub('.*_(\\dx\\d)\\.csv', '\\1', basename(f))
    read.csv(f) %>%
      mutate(Matrix.size = matrix_size)
  }) %>%
  bind_rows() %>%
  filter(Status=="APPROVED")

overall_N <- nrow(df.demographics)
overall_mean_age <- mean(as.numeric(df.demographics$Age), na.rm=TRUE)
overall_median_age <- median(as.numeric(df.demographics$Age), na.rm=TRUE)
overall_sd_age <- sd(as.numeric(df.demographics$Age), na.rm=TRUE)
overall_age_range <- range(as.numeric(df.demographics$Age), na.rm=TRUE)

N_nationalities <- length(unique(df.demographics$Nationality))
N_languages <- length(unique(df.demographics$Language))

# Gender distribution
gender_counts <- table(df.demographics$Sex)
n_female <- gender_counts["Female"]
n_male <- gender_counts["Male"]
n_other <- sum(gender_counts[!names(gender_counts) %in% c("Female", "Male")], na.rm=TRUE)

df.demographics.group_summary <- df.demographics %>%
  group_by(Matrix.size) %>%
  summarise(N = n(),
            mean_age = mean(as.numeric(Age), na.rm=TRUE),
            sd_age = sd(as.numeric(Age), na.rm=TRUE),
            min_age = min(as.numeric(Age), na.rm=TRUE),
            max_age = max(as.numeric(Age), na.rm=TRUE))

group_N <- first(df.demographics.group_summary$N)
N_5x5 <- df.demographics.group_summary %>%
  filter(Matrix.size=="5x5") %>%
  pull(N)
```

We recruited `r overall_N` participants (`r n_female` female, `r n_male` male) on the online recruitment platform Prolific, screening for participants with an approval rating above 95% from previous studies. Participants ranged in age from `r overall_age_range[1]` to `r overall_age_range[2]` years ($\mu$=`r round(overall_mean_age, 1)`, Mdn=`r overall_median_age`, $\sigma$=`r round(overall_sd_age, 1)`), representing `r N_nationalities` nationalities and `r N_languages` primary languages. Participants were compensated at $12.00 per hour, with expected completion time varying by condition (~20-40 minutes). All participants provided informed consent prior to beginning the experiment. The study was approved by the Institutional Review Board at the MGH Institute of Health Professions.

## Probabilistic Serial Reaction Time Task
::: {#example-trial-screen}
![An example trial screen in the 8-position condition of the experiment]("../assets/example-trial-screen.png"){width=80%}
:::
Like other serial reaction time task designs, our experiment tasks participants to respond to a visual stimulus that appears in one of several evenly-spaced positions on screen as quickly and accurately as possible by pressing a corresponding key on the keyboard. In our implementation, this visual stimulus is a mole stylishly clad a bright red bib and matching sunglasses (Figure); and a schematic of each position-to-keyboard mapping for each condition is shown in (Table). Participants were evenly divided into 5 groups of `r group_N` per condition, with the conditions differing in the number of positions (4, 5, 6, 7, 8) the mole can appear in.

A participant is first given a text-based tutorial accompanied by an animated demonstration on which key to press in response to each position, then instructed to work through a set of practice trials where each position is visited twice in random order. After the practice section, the participant moves on to complete `r EXPERIMENT_CONFIG$n_blocks` blocks of trials, each separated with a self-paced break. Each block consists of trials 10x the number of positions in the participant's assigned condition. This design choice results in longer blocks for conditions with more positions, but ensures each position is visited an equal number of times on average across conditions. In both practice and main trials, participants are given feedback on correctness via a pop-up short message (a checkmark vs. "Try again!" + an error tone), and allowed to retry each failed trial until they respond correctly. Following standard SRTT protocol, there is also a 120ms response-stimulus interval (RSI) between trials [TODO: cite]. We find during piloting that allowing retries, combined with the 120ms RSI, prevents participants from making compensatory errors, where they unintentionally press the wrong key in the next trial in an attempt to correct their current trial. After each block, participants are given adaptive feedback based on their accuracy and speed. At the end of the experiment, participants complete a brief questionnaire probing their explicit awareness of any patterns in the mole's appearances (Table).

In addition to our dapper mole, a number of design choices were made to facilitate participant understanding and engagement. During the practice phase, each position on screen is labelled with its corresponding key character (e.g. "A", "S", "D") to help familiarize participants with the keyboard mappings. These key labels disappear in the main trials to prevent explicitly encoding of the sequence of positions via their character labels, but reappear during retry of failed trials. To make the correspondence between the positions on screen and keyboard keys as automatic and intuitive as possible, we chose to use conventional QWERTY-based finger layouts for the key mappings across conditions (Table). We found during piloting that while this decision helped reduce cognitive load from learning novel finger placements, the larger gap between keys "F" and "J" on the keyboard introduced a discrepancy between the evenly-spaced on-screen positions and the unevenly spaced keyboard keys. This made participants more prone to making errors in the positions towards the middle of the screen compared to those on the outer edges, especially when number of positions increases [TODO: maybe run stats on pilot to find this effect]; and was not mitigated by shifting either hand's placement to close the extra gap, because the positions were still corresponding half to one hand and half to the other. After further piloting testing different visual aids, we settled on adding two hands visually to the bottom of the screen, each finger aligned with its target position (Figure). We received verbal feedback that this visual aid helped participants better map the spatial layout of the on-screen positions to their corresponding keys. Lastly, the visual design of the "positions" on screen mimicked blank 3D keyboard keys that light up in pink when the mole appears on top, and look visibly "pressed down" when the participant presses the corresponding keyboard key. This design choice links the on-screen positions diegetically to the physical keyboard keys to maximally reduce mental distance between the two. This is important to enforce as much learning via implicit motor memory as possible, rather than via visual-spatial memory of the on-screen positions.

## Transition Matrices
Within each block, the sequence of positions is generated based on a transition matrix specific to the participant's assigned condition (see Transition Matrices section below for details). 
The sequence of positions is generated based on transition matrices of varying sizes, which define the probabilities of transitioning from one position to another.

Our experiment involves a set of keyuses transition matrices to generate the sequence of positions in which a mole appears. Each matrix defines the probabilities of transitioning from one position to another on the screen, with the size of the matrix corresponding to the number of positions. For example, a 4x4 matrix defines transitions among 4 positions, while an 8x8 matrix defines transitions among 8 positions.

Between-subjects manipulation of the number of positions to handle, which is the same thing as the size of the transition matrix used to generate the position sequence. Participants are randomly assigned to one of five matrix size conditions (4x4, 5x5, 6x6, 7x7, 8x8). The transition matrix describes the number of positions on screen to respond to, and the probabilistic structure the transitions between positions follow. Because larger matrix sizes/sequences with more positions require more trials for the participant to observe the same number of trials on average for each position compared to smaller matrix sizes, we also vary the total number of trials across conditions, setting it as 20 blocks \* 10 \* matrix_length for each condition. We also vary the total number of practice trials similarly, with each condition getting 2 \* matrix_length number of practice trials.

## Hypotheses

## Matrix Construction and Verification

# Method

## Participants

## Protocol

## Materials

# Results

## H0

## H1

## H2

## H3

# Discussion

# References

::: {#refs}
:::

